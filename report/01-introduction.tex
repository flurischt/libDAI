
\section{Introduction}\label{sec:intro}
%<Introduction of the Introduction>
% NJU:
% I'd emphasise the Belief Propagation, because
% 1) it was the initial motivation to work with this topic
% 2) most of our improvements are applicable to general BP and not just our example

Whether you are planing to segment an image \cite{1544822}, recognize speech \cite{5373446} or analyze medical datasets \cite{bailly2011finding}, \textit{Belief Propagation} (BP) plays an important role in all these research areas. This is due to the very general nature of the BP algorithm which allows to approximate the probabilities for certain events. In recent years, BP has also been applied successfully in the domain of recommender systems \cite{Ha:2012:TRT:2396761.2398636}. Popularized by the Netflix challenge and E-commerce shops such as Amazon, recommender systems try to predict which items a user wants to see based on their previous ratings as well as the ratings of other, often similar, users. BP can be used to compute the probability of a user to like a particular item. Given these probabilities we are able to rank items and output the Top-N items for the given user.

 
%The work at hand presents a run-time optimized implementation of loopy Belief Propagation, tuned for a Recommender System. In the following, we quickly motivate our work and present the structure of this document.


%Do not start the introduction with the abstract or a slightly modified
%version. It follows a possible structure of the introduction. 
%Note that the structure can be modified, but the
%content should be the same. Introduction and abstract should fill at most the first page, better less.

% Elias: We should keep that in mind because the introduction to the introduction sounds quite similiar to an abstract.

\mypar{Motivation} 
While the results of Jiwoon Ha et al.\cite{Ha:2012:TRT:2396761.2398636} look very promising, one problem is that BP takes a long time to converge. Because we need to run BP once for every user (to predict their ratings), the system seems to be unusable for a large number of users. In our initial tests a baseline implementation took about 21 hours to predict the ratings on a 100k Movielens dataset \cite{riedl1998movielens}. In order to make this approach feasible, a  run-time efficient implementation of the BP algorithm is needed.

\mypar{Related work} 
We evaluated two popular open-source C++ frameworks for graph-based inference that implement the BP algorithm in a generic way: \textit{libDAI} \cite{Mooij_libDAI_10} on the one hand is a clean and accessible piece of software, whereas \textit{OpenGM} \cite{andres2012opengm} on the other hand is written with a higher degree of abstraction. We chose libDAI as our reference, because it offers a native implementation of \textit{residual} BP. 

In the following, we briefly sketch the \textit{Top-N Recommender System based on Residual Belief Propagation} in section \ref{sec:background} before we inform the reader in section \ref{sec:method} about the optimization techniques that have been applied. The results are presented in section \ref{sec:results}.
